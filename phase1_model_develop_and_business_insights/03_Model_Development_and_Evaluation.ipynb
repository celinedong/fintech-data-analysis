{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654749a6",
   "metadata": {},
   "source": [
    "# 03. Model Development & Evaluation\n",
    "\n",
    "## 1. Objective\n",
    "In this notebook, we develop and compare multiple machine learning models to predict loan defaults. We will leverage the preprocessing and resampling pipeline developed in Part 02 to ensure a fair and rigorous comparison.\n",
    "\n",
    "### 1.1 Tasks\n",
    "* **Baseline Modeling**: Establish a performance floor with Logistic Regression.\n",
    "* **Ensemble Methods**: Implement Random Forest and XGBoost to capture complex, non-linear patterns.\n",
    "* **Hyperparameter Tuning**: Optimize the champion model for the best balance of Precision and Recall.\n",
    "* **Model Interpretation**: Use SHAP values to demystify the \"black box\" and provide business transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cd1b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment ready for model development.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "# Modeling & Evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc, f1_score\n",
    "\n",
    "# Imbalance Handling\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Environment ready for model development.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79470e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define absolute paths for portability\n",
    "DATA_DIR = r\"C:\\dev\\quant_project\\homework\\data_storage\"\n",
    "MODEL_DIR = r\"C:\\dev\\quant_project\\homework\\model_storage\"\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9de6c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Bridge successful. Raw training size: 4000 samples.\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# BRIDGE: Restoring Part 02 context for independent execution\n",
    "# =================================================================\n",
    "\n",
    "# 1. Load Original Data\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, 'loan_data.csv'))\n",
    "\n",
    "# 2. Domain Feature Engineering\n",
    "def engineer_features(input_df):\n",
    "    df_eng = input_df.copy()\n",
    "    df_eng['loan_to_income'] = df_eng['loan_amount'] / (df_eng['annual_income'] + 1e-6)\n",
    "    df_eng['rev_to_loan_ratio'] = (df_eng['monthly_revenue'] * 12) / (df_eng['loan_amount'] + 1e-6)\n",
    "    df_eng['rev_per_employee'] = (df_eng['monthly_revenue'] * 12) / (df_eng['num_employees'] + 1)\n",
    "    \n",
    "    bins = [300, 580, 670, 740, 800, 850]\n",
    "    labels = ['High_Risk', 'Subprime', 'Average', 'Good', 'Excellent']\n",
    "    df_eng['credit_tier'] = pd.cut(df_eng['credit_score'], bins=bins, labels=labels)\n",
    "    return df_eng\n",
    "\n",
    "df_featured = engineer_features(df)\n",
    "\n",
    "# 3. Preprocessor Definition\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = ['annual_income', 'credit_score', 'loan_amount', 'years_in_business', \n",
    "                    'num_employees', 'previous_loans', 'debt_to_income_ratio', \n",
    "                    'monthly_revenue', 'loan_to_income', 'rev_to_loan_ratio', 'rev_per_employee']\n",
    "\n",
    "categorical_features = ['loan_purpose', 'industry', 'has_collateral', \n",
    "                        'education_level', 'geographic_region', 'credit_tier']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numeric_features),\n",
    "    ('cat', Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='missing')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]), categorical_features)\n",
    "])\n",
    "\n",
    "# 4. Stratified Split (Maintaining the ~22.5% default rate)\n",
    "X = df_featured.drop(columns=['application_id', 'default'])\n",
    "y = df_featured['default']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"‚úÖ Bridge successful. Raw training size: {len(X_train)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007ce72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resampling Verification ---\n",
      "Original Training Size: 4000\n",
      "Resampled Training Size: 4651\n",
      "Default Samples (Original): 899\n",
      "Default Samples (After SMOTE): 1550\n",
      "Post-SMOTE Default Rate: 33.33%\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# VALIDATION: Verifying Resampled Training Volume\n",
    "# We perform a manual check to ensure SMOTE is correctly \n",
    "# augmenting the minority class before it hits the model.\n",
    "# =================================================================\n",
    "\n",
    "# 1. Apply preprocessing (SMOTE requires numerical inputs)\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# 2. Manually apply SMOTE for inspection\n",
    "# We use sampling_strategy=0.5 (Minority will be 50% of the Majority)\n",
    "sm = SMOTE(random_state=42, sampling_strategy=0.5)\n",
    "X_res, y_res = sm.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "print(f\"--- Resampling Verification ---\")\n",
    "print(f\"Original Training Size: {len(X_train)}\")\n",
    "print(f\"Resampled Training Size: {len(X_res)}\")\n",
    "print(f\"Default Samples (Original): {y_train.sum()}\")\n",
    "print(f\"Default Samples (After SMOTE): {y_res.sum()}\")\n",
    "print(f\"Post-SMOTE Default Rate: {y_res.mean():.2%}\")\n",
    "\n",
    "# Note: The 'full_pipeline' will handle this automatically during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c7a78",
   "metadata": {},
   "source": [
    "## 2. Evaluation Metric Strategy: AUPRC vs. ROC\n",
    "\n",
    "In a 22.5% default environment, accuracy is a misleading metric. We prioritize **AUPRC (Area Under the Precision-Recall Curve)** for the following reasons:\n",
    "\n",
    "* **Class Imbalance**: ROC-AUC can be inflated by high True Negative counts. AUPRC focuses strictly on the \"Default\" class.\n",
    "* **Cost of Errors**: \n",
    "    * **False Negatives**: Direct capital loss (Primary Concern).\n",
    "    * **False Positives**: Opportunity cost of lost interest.\n",
    "* **Precision-Recall Tradeoff**: PR curves allow us to visualize exactly how much \"Precision\" we lose to achieve a certain \"Recall\" (e.g., catching 80% of bad loans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54f068a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_Mean</th>\n",
       "      <th>Recall_Mean</th>\n",
       "      <th>ROC_AUC_Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.648382</td>\n",
       "      <td>0.566176</td>\n",
       "      <td>0.846118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_Regression</td>\n",
       "      <td>0.642895</td>\n",
       "      <td>0.709659</td>\n",
       "      <td>0.865033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.618902</td>\n",
       "      <td>0.541688</td>\n",
       "      <td>0.831508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model   F1_Mean  Recall_Mean  ROC_AUC_Mean\n",
       "1        Random_Forest  0.648382     0.566176      0.846118\n",
       "0  Logistic_Regression  0.642895     0.709659      0.865033\n",
       "2              XGBoost  0.618902     0.541688      0.831508"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Benchmarking 3 core algorithms\n",
    "models = {\n",
    "    'Logistic_Regression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "    'Random_Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Build pipeline including SMOTE\n",
    "    clf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # 5-Fold Stratified Cross Validation\n",
    "    cv_res = cross_validate(clf_pipeline, X_train, y_train, cv=5, \n",
    "                            scoring=['f1', 'roc_auc', 'recall', 'precision'])\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'F1_Mean': cv_res['test_f1'].mean(),\n",
    "        'Recall_Mean': cv_res['test_recall'].mean(),\n",
    "        'ROC_AUC_Mean': cv_res['test_roc_auc'].mean()\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(results).sort_values(by='F1_Mean', ascending=False)\n",
    "display(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73faceeb",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning: Optimizing Ensemble Models\n",
    "\n",
    "Our initial benchmarking showed that **Logistic Regression** is a strong baseline, while **Random Forest** and **XGBoost** have potential but require tuning to overcome default parameter limitations.\n",
    "\n",
    "### 3.1 Tuning Goals:\n",
    "* **XGBoost**: Focus on preventing overfitting through `max_depth` and `learning_rate`.\n",
    "* **Random Forest**: Optimize `min_samples_leaf` and `n_estimators` to improve generalization on the minority class.\n",
    "* **Constraint**: We will continue using the **imblearn Pipeline** during Grid Search to ensure SMOTE is applied correctly within each cross-validation fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4b3c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Random Forest...\n",
      "Tuning XGBoost...\n",
      "\n",
      "‚úÖ Tuning Complete.\n",
      "Best RF Params: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__n_estimators': 100}\n",
      "Best XGB Params: {'classifier__learning_rate': 0.05, 'classifier__max_depth': 3, 'classifier__n_estimators': 100, 'classifier__scale_pos_weight': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Tuning Random Forest\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [10, 20, None],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "print(\"Tuning Random Forest...\")\n",
    "rf_grid = GridSearchCV(rf_pipeline, rf_param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# 2. Tuning XGBoost\n",
    "xgb_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [3, 5],\n",
    "    'classifier__learning_rate': [0.05, 0.1],\n",
    "    'classifier__scale_pos_weight': [1, 3] # Addresses 22.5% imbalance specifically\n",
    "}\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),\n",
    "    ('classifier', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "print(\"Tuning XGBoost...\")\n",
    "xgb_grid = GridSearchCV(xgb_pipeline, xgb_param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úÖ Tuning Complete.\")\n",
    "print(f\"Best RF Params: {rf_grid.best_params_}\")\n",
    "print(f\"Best XGB Params: {xgb_grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82619103",
   "metadata": {},
   "source": [
    "## 4. The Grand Final: Test Set Performance\n",
    "\n",
    "We now evaluate the best-tuned versions of all three candidates on the **X_test / y_test** set. This is the ultimate test of how the models will perform in a production environment at FinFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd7dd2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_F1</th>\n",
       "      <th>Test_ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned_Random_Forest</td>\n",
       "      <td>0.617778</td>\n",
       "      <td>0.808140</td>\n",
       "      <td>0.700252</td>\n",
       "      <td>0.874796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuned_XGBoost</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>0.889996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_Regression (Baseline)</td>\n",
       "      <td>0.768889</td>\n",
       "      <td>0.615658</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>0.891533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Test_Recall  Test_Precision   Test_F1  \\\n",
       "1             Tuned_Random_Forest     0.617778        0.808140  0.700252   \n",
       "2                   Tuned_XGBoost     0.626667        0.783333  0.696296   \n",
       "0  Logistic_Regression (Baseline)     0.768889        0.615658  0.683794   \n",
       "\n",
       "   Test_ROC_AUC  \n",
       "1      0.874796  \n",
       "2      0.889996  \n",
       "0      0.891533  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ Champion Model: Tuned_Random_Forest\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score, precision_score\n",
    "\n",
    "final_comparison = []\n",
    "\n",
    "# Define the finalists\n",
    "final_models = {\n",
    "    'Logistic_Regression (Baseline)': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),\n",
    "        ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "    ]),\n",
    "    'Tuned_Random_Forest': rf_grid.best_estimator_,\n",
    "    'Tuned_XGBoost': xgb_grid.best_estimator_\n",
    "}\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # Fit (LR needs fitting, others are already fitted by GridSearch)\n",
    "    if name == 'Logistic_Regression (Baseline)':\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    final_comparison.append({\n",
    "        'Model': name,\n",
    "        'Test_Recall': recall_score(y_test, y_pred),\n",
    "        'Test_Precision': precision_score(y_test, y_pred),\n",
    "        'Test_F1': f1_score(y_test, y_pred),\n",
    "        'Test_ROC_AUC': roc_auc_score(y_test, y_proba)\n",
    "    })\n",
    "\n",
    "# Output the results\n",
    "final_perf_df = pd.DataFrame(final_comparison).sort_values(by='Test_F1', ascending=False)\n",
    "display(final_perf_df)\n",
    "\n",
    "# Store the best model for Part 04\n",
    "champion_name = final_perf_df.iloc[0]['Model']\n",
    "best_model = final_models[champion_name]\n",
    "print(f\"\\nüèÜ Champion Model: {champion_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f634de9b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Model Selection & Strategic Rationale\n",
    "\n",
    "Based on the final test set evaluation, the **Tuned Random Forest** has been identified as the \"Champion Model\" by our automated scoring logic.\n",
    "\n",
    "### 4.1 Why Random Forest Won the F1-Score Title\n",
    "At the default $0.5$ classification threshold, **Random Forest** provided the most balanced performance across the portfolio:\n",
    "\n",
    "* **Optimal F1-Score ($0.700$):** As the harmonic mean of Precision and Recall, the $F1$ score rewards models that minimize both types of errors. Random Forest outperformed the baseline and XGBoost by maintaining a high degree of stability.\n",
    "* **Superior Precision ($0.808$):** This is the strongest highlight for this model. It implies that when the model flags an applicant for \"Default,\" it is correct **80.8%** of the time. This minimizes the \"False Positive\" rate, which is critical for maintaining high customer satisfaction and preventing the rejection of creditworthy applicants.\n",
    "* **Generalization Performance:** While XGBoost achieved a slightly higher ROC-AUC ($0.889$), indicating strong ranking potential, Random Forest showed better generalization at the current threshold, likely due to its inherent resistance to the noise introduced by synthetic oversampling (SMOTE).\n",
    "\n",
    "### 4.2 Cost-Based Model Selection\n",
    "In a real-world production environment, we don't just select the highest $F1$; we select the model that minimizes the **Total Economic Cost**. The optimal choice depends on the specific cost weights assigned by the risk committee:\n",
    "\n",
    "$$Total\\ Cost = (FN \\times Cost_{Default}) + (FP \\times Cost_{Opportunity})$$\n",
    "\n",
    "\n",
    "\n",
    "* **Case for Logistic Regression (High Recall: $0.768$):** If the cost of a default ($FN$) is significantly higher (e.g., $10\\times$) than the cost of losing a customer ($FP$), Logistic Regression might be the preferred choice despite its lower $F1$. It captures nearly **77%** of all potential defaulters, providing maximum capital protection.\n",
    "* **Case for Random Forest (High Precision: $0.808$):** If FinFlow is in a \"Growth Phase\" where customer acquisition cost is high and market share is the priority, the high Precision of Random Forest is more valuable. It ensures that only the most certain risks are rejected, keeping the \"Approval Funnel\" healthy.\n",
    "\n",
    "### 4.3 Choose Random Forest here\n",
    "We will proceed with **Tuned Random Forest** as our primary model for the next phase. Its high precision offers a stable foundation for automated lending. In the final notebook, we will explore **Threshold Tuning** to see if we can further increase the Recall of this champion model without significantly degrading its precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb41d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Reconstruct feature names from the best_model pipeline\n",
    "cat_encoder = best_model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "cat_cols = list(cat_encoder.get_feature_names_out(categorical_features))\n",
    "all_feature_names = numeric_features + cat_cols\n",
    "\n",
    "# 2. Package everything into a dictionary\n",
    "model_artifacts = {\n",
    "    'model': best_model,\n",
    "    'all_feature_names': all_feature_names,\n",
    "    'numeric_features': numeric_features,\n",
    "    'categorical_features': categorical_features\n",
    "}\n",
    "\n",
    "# 3. Save the artifacts file\n",
    "model_save_path = os.path.join(MODEL_DIR, 'finflow_artifacts.joblib')\n",
    "joblib.dump(model_artifacts, model_save_path)\n",
    "\n",
    "# 4. Save the raw datasets for consistency in Part 04\n",
    "X_train.to_csv(os.path.join(DATA_DIR, 'X_train.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(DATA_DIR, 'X_test.csv'), index=False)\n",
    "y_train.to_csv(os.path.join(DATA_DIR, 'y_train.csv'), index=False)\n",
    "y_test.to_csv(os.path.join(DATA_DIR, 'y_test.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FinFlow Senior DS)",
   "language": "python",
   "name": "finflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
